# 제8장: 선형 회귀 입문

## 목차

- 8.1 직선 적합, 잔차, 상관관계
- 8.2 최소제곱 회귀
- 8.3 선형 회귀에서의 이상치 유형
- 8.4 선형 회귀에 대한 추론

---

선형 회귀는 매우 강력한 통계 기법이다. 많은 사람들이 뉴스에서 산점도 위에 직선이 덧씌워진 것을 보며 회귀에 대해 어느 정도 친숙함을 갖고 있다. 선형 모형은 예측에 사용되거나 두 수치형 변수 사이에 선형 관계가 있는지 평가하는 데 사용될 수 있다.

---

## 8.1 직선 적합, 잔차, 상관관계

직선 적합 과정에 대해 깊이 생각하는 것이 도움이 된다. 이 절에서는 선형 모형의 형태를 정의하고, 좋은 적합이란 무엇인지에 대한 기준을 탐구하며, 상관관계라는 새로운 통계량을 소개한다.

### 8.1.1 데이터에 직선 적합하기

**선형 회귀**(Linear Regression)는 두 변수 x와 y 사이의 관계가 약간의 오차를 가진 직선으로 모형화될 수 있는 데이터에 직선을 적합하는 통계적 방법이다:

**y = β₀ + β₁x + ε**

여기서 β₀와 β₁은 모형의 **모수**(parameters)를 나타내며, 오차는 ε로 나타낸다. x를 사용하여 y를 예측할 때, x를 **설명변수** 또는 **예측변수**라고 부르고, y를 **반응변수**라고 부른다.

### 8.1.2 주머니쥐 머리 길이를 예측하기 위한 선형 회귀 사용

데이터는 호주의 주머니쥐(possum)에 대해 수집되었으며, 각 관측치에서 주머니쥐의 전체 길이와 머리 길이가 측정되었다.

직선 적합에서 각 관측치에 대해 직선 위의 예측값은 다음과 같다:

**ŷ = b₀ + b₁x**

#### 예제 8.1

**문제**: 주머니쥐 데이터에 대해 적합한 직선 방정식은 ŷ = 41 + 0.59x이다. 전체 길이가 80cm인 주머니쥐의 머리 길이를 예측하라.

**풀이**: 방정식에 x = 80을 대입한다:

ŷ = 41 + 0.59 × 80 = 41 + 47.2 = 88.2 mm

전체 길이가 80cm인 주머니쥐의 머리 길이는 약 88.2mm로 예측된다.

---

### 8.1.3 잔차

**잔차(residuals)**는 관측값과 선형 모형의 예측값 사이의 차이이다:

**eᵢ = yᵢ - ŷᵢ**

- 양의 잔차: 직선이 **과소예측**
- 음의 잔차: 직선이 **과대예측**

#### 예제 8.2

**문제**: 한 주머니쥐의 머리 길이가 86.7mm이고 전체 길이가 84cm이다. 잔차는?

**풀이**:
- 예측값: ŷ = 41 + 0.59 × 84 = 90.56 mm
- 잔차: e = 86.7 - 90.56 = -3.86 mm

음의 잔차이므로 모형이 과대예측했다.

---

### 8.1.4 상관관계로 선형 관계 설명하기

**상관관계(correlation)**는 항상 -1과 1 사이의 값을 가지며, 두 변수 사이의 선형 관계의 강도를 설명한다. 상관관계를 R로 표기한다.

**상관계수 해석 지침:**

| 상관계수 R | 해석 |
|:---:|:---|
| R = 1 | 완벽한 양의 선형 관계 |
| 0.7 ≤ R < 1 | 강한 양의 선형 관계 |
| 0.3 ≤ R < 0.7 | 중간 정도의 양의 선형 관계 |
| 0 < R < 0.3 | 약한 양의 선형 관계 |
| R = 0 | 선형 관계 없음 |
| -0.3 < R < 0 | 약한 음의 선형 관계 |
| -0.7 < R ≤ -0.3 | 중간 정도의 음의 선형 관계 |
| -1 < R ≤ -0.7 | 강한 음의 선형 관계 |
| R = -1 | 완벽한 음의 선형 관계 |

---

> **새로운 시각: 상관관계 ≠ 인과관계**
>
> 두 변수 사이에 강한 상관관계가 있다고 해서 한 변수가 다른 변수를 "유발"한다고 결론 내릴 수 없다. 예를 들어, 아이스크림 판매량과 익사 사고 사이에 양의 상관관계가 있지만, 아이스크림이 익사를 유발하는 것은 아니다. 공통 원인(더운 날씨)이 두 변수에 영향을 미친다.

---

## 8.2 최소제곱 회귀

### 8.2.1 엘름허스트 대학 신입생에 대한 장학금

엘름허스트 대학의 50명 신입생에 대해 가족 소득과 대학에서 받은 장학금 금액이 수집되었다.

### 8.2.2 최적의 직선을 찾기 위한 객관적 측도

**최소제곱 기준**을 최소화하는 직선을 **최소제곱선(least squares line)**이라고 한다:

**e₁² + e₂² + ... + eₙ²** 을 최소화

### 8.2.3 최소제곱선을 위한 조건

최소제곱선을 적합할 때, 다음 조건들이 필요하다:

1. **선형성** (Linearity): 데이터가 선형 추세를 보여야 한다.
2. **거의 정규인 잔차**: 잔차가 거의 정규분포를 따라야 한다.
3. **등분산성** (Constant variability): 점들의 변동성이 대략 일정해야 한다.
4. **독립 관측치**: 관측치들이 서로 독립이어야 한다.

### 8.2.4 최소제곱선 구하기

**기울기 추정:**

b₁ = (sᵧ / sₓ) × R

여기서 R은 상관계수, sₓ와 sᵧ는 설명변수와 반응변수의 표본표준편차

**절편 추정** (직선이 (x̄, ȳ)를 지남):

b₀ = ȳ - b₁ × x̄

#### 예제 8.8

**문제**: 엘름허스트 대학 데이터에서 상관계수 R = -0.499, 가족 소득 표준편차 $63,001, 장학금 표준편차 $5,456이다. 기울기를 계산하라.

**풀이**:

b₁ = (5456 / 63001) × (-0.499) = -0.0431

#### 예제 8.9

**문제**: 장학금 평균 $19,939, 가족 소득 평균 $101,784이다. 절편을 계산하라.

**풀이**:

b₀ = 19939 - (-0.0431) × 101784 = 19939 + 4387 = 24326

**회귀 방정식**: ŷ = 24,326 - 0.0431 × (가족소득)

---

### 8.2.5 회귀 모형 모수 추정치 해석

- **절편 (b₀)**: x = 0일 때 y의 예측값. 항상 의미 있는 것은 아님.
- **기울기 (b₁)**: x가 1단위 증가할 때 y의 예측된 평균 변화량.

### 8.2.6 외삽의 위험성

**외삽**(Extrapolation): 원래 데이터의 범위 밖의 값에 모형 추정치를 적용하는 것. 외삽하면 신뢰할 수 없는 예측을 하게 된다.

### 8.2.7 R²를 사용하여 적합의 강도 설명하기

**R²**(결정계수)는 모형에 의해 설명되는 반응변수의 변동 비율을 나타낸다.

R² = 1 - (잔차의 변동성 / 결과의 변동성)

단순 선형 회귀에서 R²는 상관계수 R의 제곱과 같다.

### 8.2.8 두 수준의 범주형 예측변수

범주형 변수도 예측에 유용하다. **지시변수**(indicator variable)를 사용하여 범주를 수치로 변환한다:

**cond_new 정의:**
- cond_new = 1 (새 것이면)
- cond_new = 0 (중고이면)

**모형**: ŷ = 42.87 + 10.90 × cond_new

**해석**:
- 절편 (42.87): 중고 게임의 평균 판매 가격
- 기울기 (10.90): 새 게임은 평균적으로 중고보다 $10.90 더 비쌈

---

## 8.2절 연습문제

### 연습문제 8.23: Coast Starlight

**데이터**:
- 평균 이동 시간: 129분, 표준편차: 113분
- 평균 거리: 108마일, 표준편차: 99마일
- 상관계수: 0.636

**풀이**:

b₁ = 0.636 × (113/99) = 0.726

b₀ = 129 - 0.726 × 108 = 50.6

**회귀선**: ŷ = 50.6 + 0.726 × (거리)

---

### 연습문제 8.25: 살인과 빈곤, 파트 I

**회귀 출력**:

| 변수 | Estimate | Std. Error | t value | Pr(>t) |
|:---|---:|---:|---:|---:|
| (Intercept) | -29.901 | 7.789 | -3.839 | 0.001 |
| poverty% | 2.559 | 0.390 | 6.562 | 0.000 |

s = 5.512, R² = 70.52%

**풀이**:

(a) 선형 모형: ŷ = -29.901 + 2.559 × (빈곤율%)

(b) 절편: 빈곤율이 0%일 때 살인율은 -29.901 (의미 없음, 음수 불가능)

(c) 기울기: 빈곤율이 1% 포인트 높아질 때 살인율이 2.559건 증가

(d) R²: 살인율 변동의 70.52%가 빈곤율에 의해 설명됨

(e) 상관계수: R = √0.7052 = 0.84 (기울기가 양수이므로 양수)

---

## 8.3 선형 회귀에서의 이상치 유형

회귀에서 **이상치**(outliers)는 점들의 구름에서 멀리 떨어진 관측치이다.

**이상치 유형:**

1. **높은 지렛대 점** (High leverage point): x 방향으로 데이터 중심에서 멀리 떨어진 점
2. **영향력 있는 점** (Influential point): 실제로 회귀선의 기울기에 상당한 영향을 미치는 점
3. **이상치 (Outlier)**: 다른 점들의 패턴에서 벗어난 점

> **새로운 시각: 이상치 처리**
>
> 이상치를 단순히 제거하지 마라. 매우 좋은 이유 없이는 제거해서는 안 된다. 이상치가 가장 중요한 발견일 수 있다.

---

## 8.4 선형 회귀에 대한 추론

### 8.4.1 기울기에 대한 가설 검정

- **H₀**: β₁ = 0 (참 선형 모형의 기울기는 0)
- **Hₐ**: β₁ ≠ 0 (참 선형 모형의 기울기는 0이 아님)

### 8.4.2 소프트웨어의 회귀 출력 이해하기

**중간선거와 실업률 회귀 출력**:

| 변수 | Estimate | Std. Error | t value | Pr(>t) |
|:---|---:|---:|---:|---:|
| (Intercept) | -7.3644 | 5.1553 | -1.43 | 0.1646 |
| unemp | -0.8897 | 0.8350 | -1.07 | 0.2961 |

df = 27

**검정 통계량**: T = (-0.8897 - 0) / 0.8350 = -1.07

**p-값** = 0.2961 > 0.05 → H₀ 기각 실패

### 8.4.3 계수에 대한 신뢰구간

**공식**: bᵢ ± t*_df × SE_bᵢ

**예제**: 엘름허스트 데이터, 95% 신뢰구간

- 점추정치: -0.0431
- 표준오차: SE = 0.0108
- df = 48, t* = 2.01

**계산**: -0.0431 ± 2.01 × 0.0108 = (-0.0648, -0.0214)

**해석**: 가족 소득이 $1 증가할 때마다, 장학금은 평균적으로 $0.0214에서 $0.0648 감소할 것으로 95% 신뢰한다.

---

## 8.4절 연습문제

### 연습문제 8.31: 신체 측정

**회귀 출력** (키로 체중 예측, 507명):

| 변수 | Estimate | Std. Error | t value | Pr(>t) |
|:---|---:|---:|---:|---:|
| (Intercept) | -105.0113 | 7.5394 | -13.93 | 0.0000 |
| height | 1.0176 | 0.0440 | 23.13 | 0.0000 |

**풀이**:

(a) 키와 체중 사이에 양의, 강한 선형 관계가 있다.

(b) 회귀선: ŷ = -105.01 + 1.02 × 키
- 기울기: 키 1cm 증가 시 체중 약 1.02kg 증가
- 절편: 의미 없음 (키 0cm 불가능)

(c) p-값 < 0.05이므로 H₀ 기각. 강력한 증거 있음.

(d) R² = 0.72² = 0.52 (체중 변동의 52%가 키에 의해 설명됨)

---

### 연습문제 8.35: 살인과 빈곤, 파트 II

**(c) 95% 신뢰구간** (n=20, df=18, t* = 2.10):

2.559 ± 2.10 × 0.390 = (1.74, 3.38)

**(d)** 가설 검정(H₀ 기각)과 신뢰구간(0 미포함)의 결과가 일관된다.

---

### 연습문제 8.37: 참/거짓

(a) 상관계수 -0.90은 상관관계 0.5보다 더 강한 선형 관계를 나타낸다.

**정답**: 참. |-0.90| = 0.90 > |0.5| = 0.5

(b) 상관관계는 두 변수 간의 연관성 측도이다.

**정답**: 거짓. 상관관계는 두 **수치형** 변수 간의 **선형** 연관성 측도이다.

---

> **새로운 시각: 회귀분석의 실용적 적용**
>
> 1. **탐색적 데이터 분석 먼저**: 회귀 전에 항상 산점도를 그려 관계를 시각적으로 확인
> 2. **조건 검증**: 4가지 조건(선형성, 정규성, 등분산성, 독립성)을 항상 확인
> 3. **외삽 주의**: 데이터 범위 밖의 예측은 신뢰할 수 없음
> 4. **인과관계 주의**: 상관관계가 인과관계를 의미하지 않음
> 5. **R² 해석 주의**: R²가 높아도 모형이 유용하지 않을 수 있음

---

## Python 코드: 선형 회귀 분석

```python
import numpy as np
import matplotlib.pyplot as plt
from scipy import stats

# 데이터 입력
x = np.array([75, 77, 80, 82, 85, 87, 89, 91, 93, 95])
y = np.array([85, 87, 89, 90, 92, 94, 95, 97, 98, 100])

# 기본 통계량
x_mean, y_mean = np.mean(x), np.mean(y)
x_std, y_std = np.std(x, ddof=1), np.std(y, ddof=1)
r = np.corrcoef(x, y)[0, 1]

# 최소제곱 추정치
b1 = r * (y_std / x_std)
b0 = y_mean - b1 * x_mean

print(f"상관계수: R = {r:.4f}")
print(f"기울기: b1 = {b1:.4f}")
print(f"절편: b0 = {b0:.4f}")
print(f"R² = {r**2:.4f}")
print(f"회귀선: ŷ = {b0:.2f} + {b1:.4f}x")

# 시각화
plt.figure(figsize=(10, 6))
plt.scatter(x, y, s=60, alpha=0.7, label='데이터')
x_line = np.linspace(x.min()-2, x.max()+2, 100)
plt.plot(x_line, b0 + b1*x_line, 'r-', lw=2, label=f'ŷ = {b0:.2f} + {b1:.4f}x')
plt.xlabel('X')
plt.ylabel('Y')
plt.title('선형 회귀')
plt.legend()
plt.grid(True, alpha=0.3)
plt.show()
```

---

*OpenIntro Statistics 제8장 한국어 번역*
